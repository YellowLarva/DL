import numpy as np

# perceptron function
def perceptron(X, y, alpha=0.1, iterations=100):
    m, n = X.shape
    X = np.insert(X, 0, 1, axis=1)  # add bias term
    w = np.zeros((n + 1, 1))

    for i in range(iterations):
        for j in range(m):
            z = np.dot(X[j], w)
            if z > 0:
                y_pred = 1
            else:
                y_pred = 0
            error = y[j] - y_pred
            w = w + alpha * error * X[j][:, np.newaxis]

    return w

# AND function
X_and = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
y_and = np.array([[0], [0], [0], [1]])
w_and = perceptron(X_and, y_and)
print('Weights for AND function:', w_and)

# OR function
X_or = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
y_or = np.array([[0], [1], [1], [1]])
w_or = perceptron(X_or, y_or)
print('Weights for OR function:', w_or)

# NOT function
X_not = np.array([[0], [1]])
y_not = np.array([[1], [0]])
w_not = perceptron(X_not, y_not)
print('Weights for NOT function:', w_not)

# NOR function
X_nor = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
y_nor = np.array([[1], [0], [0], [0]])
w_nor = perceptron(X_nor, y_nor)
print('Weights for NOR function:', w_nor)

# NAND function
X_nand = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
y_nand = np.array([[1], [1], [1], [0]])
w_nand = perceptron(X_nand, y_nand)
print('Weights for NAND function:', w_nand)
